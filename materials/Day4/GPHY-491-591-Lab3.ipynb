{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3-1: Data Science for Sustainability (Finally!) üõ∞Ô∏èüåç\n",
    "\n",
    "![ntl](./assets/ntl.jpg)\n",
    "\n",
    "Data science for sustainability is a ***broad*** topic. But generally, ansering questions about how to create a more sustainabile future we need two types of data: human and environment. These types of data are inharently geospatial because they **map** human and environment phenomena on planet earth. [<span class=\"codeb\">Geographic Information Systems</span>](https://en.wikipedia.org/wiki/Geographic_information_system) allow for visualizing, manipulating, and analyzing human and environmental geographic data. But GIS platforms have limited utility because (1) it can be difficult to reproduce work flows and (2) they may not be able to process large quantities of data efficent. Further, GIS platforms tend to be a black box that do not allow you to fully understand how your data is being processed. \n",
    "\n",
    "Thankfully, open-source data science evangelists have developed a suite of geospatial data science packages ‚Äì such as [<span class=\"codeb\">GeoPandas</span>](https://geopandas.org) ‚Äì in Python that build on [Numpy](https://numpy.org), [<span class=\"codeb\">Pandas</span>](https://pandas.pydata.org), and other commonly used Python packages. As such, many of the data structures and functions are similar for packages like <span class=\"code\">Geopandas</span> as they are in [<span class=\"codeb\">Pandas</span>](https://geopandas.org). \n",
    "\n",
    "In this session, we will overview how GeoSpatial data can be analysized in Python. Those of you who have a background in GIS will notice many parallels with ArcGIS and QGIS. The advantage here, is you will have budding cababilities to build your own GIS, but with Python. \n",
    " \n",
    "<p style=\"height:1pt\"> </p>\n",
    "\n",
    "<div class=\"boxhead2\">\n",
    "    Session Topics\n",
    "</div>\n",
    "\n",
    "<div class=\"boxtext2\">\n",
    "<ul class=\"a\">\n",
    "    <li> üìå Introduction to <span class=\"codeb\">matplotlib.pyplot</span> </li>\n",
    "    <ul class=\"b\">\n",
    "        <li> Anatomy of a plot </li>\n",
    "    </ul>\n",
    "    <li> üìå Basic plotting </li>\n",
    "    <ul class=\"b\">\n",
    "        <li> Line plots using <code>plt.plot()</code> </li>\n",
    "        <li> Scatter plots using <code>plt.scatter()</code> </li>\n",
    "    </ul>\n",
    "    <li> üìå Keyword arguments </li>\n",
    "    <ul class=\"b\">\n",
    "        <li> Colors </li>\n",
    "        <li> Linestyles </li>\n",
    "        <li> Markers </li>\n",
    "        <li> Explicit definitions vs. shortcuts </li>\n",
    "    </ul>    \n",
    "    <li> üìå Axes settings </li>\n",
    "    <ul class=\"b\">\n",
    "        <li> Limits, labels, and ticks </li>\n",
    "        <li> Legends + titles </li>\n",
    "    </ul>\n",
    "    <li> üìå Subplots + multiple axes </li>\n",
    "    <ul class=\"b\">\n",
    "        <li> <span class=\"code\">Figure</span> vs. <span class=\"code\">Axes</span> methods </li>\n",
    "    </ul>\n",
    "    <li> üìå Working with real data </li>\n",
    "    \n",
    "    \n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<hr style=\"border-top: 0.2px solid gray; margin-top: 12pt; margin-bottom: 0pt\"></hr>\n",
    "\n",
    "### Instructions\n",
    "We will work through this notebook together. To run a cell, click on the cell and press \"Shift\" + \"Enter\" or click the \"Run\" button in the toolbar at the top. \n",
    "\n",
    "<p style=\"color:#408000; font-weight: bold\"> üêç &nbsp; &nbsp; This symbol designates an important note about Python structure, syntax, or another quirk.  </p>\n",
    "\n",
    "<p style=\"color:#008C96; font-weight: bold\"> ‚ñ∂Ô∏è &nbsp; &nbsp; This symbol designates a cell with code to be run.  </p>\n",
    "\n",
    "<p style=\"color:#008C96; font-weight: bold\"> ‚úèÔ∏è &nbsp; &nbsp; This symbol designates a partially coded cell with an example.  </p>\n",
    "\n",
    "<hr style=\"border-top: 1px solid gray; margin-top: 24px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to GeoPandas\n",
    "\n",
    "<img src=\"./assets/geopands.png\">\n",
    "\n",
    "\n",
    "\n",
    "GeoPandas is an open-source Python library that ascribes geographic information to Pandas Series DataFrame objects. In other words, enables a Pandas to have a spatial dimention akin to a .shp file in a GIS platform. GeoPandas \n",
    "\n",
    "\n",
    "GeoPandas is an open source project to add support for geographic data to pandas objects. It currently implements GeoSeries and GeoDataFrame types which are subclasses of pandas.Series and pandas.DataFrame respectively. GeoPandas objects can act on shapely geometry objects and perform geometric operations.\n",
    "\n",
    "\n",
    "\n",
    "NumPy, an abbreviation for *Numerical Python*, is the core library for scientific computing in Python. In addition to manipulation of array-based data, NumPy provides an efficient way to store and operate on very large datasets. In fact, nearly all Python packages for data storage and computation are built on NumPy arrays. \n",
    "\n",
    "This exercise will provide an overview of NumPy, including how arrays are created, NumPy functions to operate on arrays, and array math. While most of the basics of the NumPy package will be covered here, there are many, many more operations, functions, and modules. As always, you should consult the [NumPy Docs](https://docs.scipy.org/doc/numpy/reference/index.html) to explore its additional functionality.\n",
    "\n",
    "Before jumping into NumPy, we should take a brief detour through importing libraries in Python. While most packages we will use ‚Äì including NumPy ‚Äì¬†are developed by third-parties, there are a number of \"standard\" packages that are built into the Python API. The following table contains a description of a few of the most useful modules worth making note of.\n",
    "\n",
    "| Module | Description | Syntax |\n",
    "| :----- | :---------- | :----- |\n",
    "| <a href=\"https://docs.python.org/3.8/library/os.html\" style=\"text-decoration: none; font-family: Lucida Console, Courier, monospace; font-weight: bold\"> os </a> | Provides access to operating system functionality | <span style=\"font-family: Lucida Console, Courier, monospace; font-weight: bold\"> import os </span> |\n",
    "| <a href=\"https://docs.python.org/3.8/library/math.html\" style=\"text-decoration: none; font-family: Lucida Console, Courier, monospace; font-weight: bold\"> math </a> | Provides access to basic mathematical functions | <span style=\"font-family: Lucida Console, Courier, monospace; font-weight: bold\"> import math </span> |\n",
    "| <a href=\"https://docs.python.org/3.8/library/random.html\" style=\"text-decoration: none; font-family: Lucida Console, Courier, monospace; font-weight: bold\"> random </a> | Implements pseudo-random number generators for various distributions | <span style=\"font-family: Lucida Console, Courier, monospace; font-weight: bold\"> import random </span> |\n",
    "| <a href=\"https://docs.python.org/3.8/library/os.html\" style=\"text-decoration: none; font-family: Lucida Console, Courier, monospace; font-weight: bold\"> datetime </a> | Supplies classes for generating and manipulating dates and times | <span style=\"font-family: Lucida Console, Courier, monospace; font-weight: bold\"> import datetime as dt </span> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 2D cartisian space (e.g. latitude and logitutue) is often sufficent for analysis, most human and environmental data is time-varing, meaning that a third dimention is often present in these datasets. Sometimes,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dir Paths\n",
    "PATH = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Depedencies\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio \n",
    "from rasterstats import zonal_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge socioeconomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Open shape files\n",
    "neighborhoods_fn = PATH+'la_county/la_county.shp'\n",
    "neighborhoods = gpd.read_file(neighborhoods_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Get socioeconomic data\n",
    "se_dir = PATH+'socioeconomic/'\n",
    "fn_out = 'ESM203_F2020_SocioEcon'\n",
    "\n",
    "# get names \n",
    "df_out = neighborhoods[['Name']]\n",
    "df_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col\n",
    "\n",
    "# loop through files and write out csv\n",
    "for fn in os.listdir(se_dir):\n",
    "    \n",
    "    col = fn.split('LA-')[1].split('.csv')[0] # Get col name\n",
    "    df = pd.read_csv(se_dir+fn) # open the fn\n",
    "\n",
    "    if df.shape[1] == 3:\n",
    "        df_out = df_out.merge(df.iloc[:,1:3], on = 'NEIGHBORHOOD', how = 'left') # merge \n",
    "    \n",
    "    elif df.shape[1] == 4: # crime\n",
    "        df_out = df_out.merge(df.iloc[:,1:4], on = 'NEIGHBORHOOD', how = 'left') # merge\n",
    "        df_out.rename(columns = {'PER CAPITA' : \"CRIME PER CAPITA\"}, inplace = True)\n",
    "        df_out.rename(columns = {'TOTAL' : \"CRIME TOTAL\"}, inplace = True)\n",
    "\n",
    "# write csv\n",
    "df_out.to_csv(PATH+fn_out+'.csv', index = False)\n",
    "\n",
    "# write shape file\n",
    "gdf_out = neighborhoods[['Name','geometry']]\n",
    "gdf_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col\n",
    "gdf_out = df_out.merge(gdf_out, on = 'NEIGHBORHOOD', how = 'right')\n",
    "gdf_out = gpd.GeoDataFrame(gdf_out)\n",
    "gdf_out.to_file(PATH+fn_out+'.shp', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make NDVI and LST from Landsat Scenes\n",
    "Will do this for two scences one spring and one summer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndvi(b4_fn, b5_fn, out_fn):\n",
    "    \"\"\"Funciton writes an NDVI image from Landsat 8. Will throw an error for 0 values in Landsat edges.\n",
    "    Args:\n",
    "        b4_fn = path to Landsat8 band 4 (red) geotif\n",
    "        b5_fn = path to Landsat8 band 5 (NIR) geotif\n",
    "        fn_out = path and name to write out ndvi file\n",
    "    \"\"\"\n",
    "    \n",
    "    meta = rasterio.open(b4_fn).meta\n",
    "    meta.update({'dtype': 'float32'})\n",
    "    band4 = rasterio.open(b4_fn).read(1) #Red\n",
    "    band5 = rasterio.open(b5_fn).read(1) #NIR\n",
    "    \n",
    "    # NDVI = (NIR ‚Äî VIS)/(NIR + VIS) \n",
    "    ndvi = np.nan_to_num((band5 - band4)/(band5 + band4))\n",
    "    ndvi = np.float32(ndvi) # reduce size\n",
    "    \n",
    "    # write our raster to disk\n",
    "    with rasterio.open(out_fn, 'w', **meta) as out:\n",
    "        out.write_band(1, ndvi)\n",
    "\n",
    "    print('NDVI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bright_temp(b_fn, fn_out, radiance_mult, radiance_add, k1, k2):\n",
    "    \n",
    "    \"\"\" Function writes a tif for Landsat8 brigthtness temp from DN. Note, this is not land surface tempature.\n",
    "    Args:\n",
    "        b_fn = file name for TIRS band\n",
    "        fn_out = path and file name to write .tif\n",
    "        radiance_mult, radiance_add, k1, k2 = all come from the Landsat8 Level 1 XXX_MTL.txt file\n",
    "    \"\"\"\n",
    "    # read & meta\n",
    "    meta = rasterio.open(b_fn).meta\n",
    "    meta.update({'dtype': 'float32'})\n",
    "    b = rasterio.open(b_fn).read(1)\n",
    "    \n",
    "    # Calculate TOA reflectance from DN:\n",
    "    toa  = (b * radiance_mult) + radiance_add\n",
    "    \n",
    "    # TOA to brightness temp from K to C\n",
    "    bright = (k2 / np.log(k1 / (toa +1)) - 273.15)\n",
    "    bright = np.float32(bright)\n",
    "    \n",
    "    # Drop Brightness values >50C\n",
    "    bright[bright >= 50] = np.nan\n",
    "    \n",
    "    # write our raster to disk\n",
    "    with rasterio.open(fn_out, 'w', **meta) as out:\n",
    "        out.write_band(1, bright)\n",
    "\n",
    "    print('Brightness temp done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make NDVI -- Summer 2020-08-20\n",
    "data_in = PATH+'landsat/Level1/LC08_L1TP_041036_20200820_20200905_01_T1/' \n",
    "b4 = data_in+'LC08_L1TP_041036_20200820_20200905_01_T1_B4.TIF'\n",
    "b5 = data_in+'LC08_L1TP_041036_20200820_20200905_01_T1_B5.TIF'\n",
    "out = PATH+'interim/NDVI_20200820.tif'\n",
    "ndvi(b4, b5, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make Brightness temp -- Summer 2020-08-20\n",
    "data_in = PATH+'landsat/Level1/LC08_L1TP_041036_20200820_20200905_01_T1/'\n",
    "b_fn = data_in+'LC08_L1TP_041036_20200820_20200905_01_T1_B10.TIF'\n",
    "fn_out = PATH+'interim/BrightTemp_20200820.tif'\n",
    "radiance_mult = 3.3420E-04\n",
    "radiance_add = 0.10000\n",
    "k1 = 774.8853\n",
    "k2 = 1321.0789\n",
    "bright_temp(b_fn, fn_out, radiance_mult, radiance_add, k1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make NDVI -- Spring 2020-04-14\n",
    "data_in = PATH+'landsat/Level1/LC08_L1TP_041036_20200414_20200423_01_T1/' \n",
    "b4 = data_in+'LC08_L1TP_041036_20200414_20200423_01_T1_B4.TIF'\n",
    "b5 = data_in+'LC08_L1TP_041036_20200414_20200423_01_T1_B5.TIF'\n",
    "out = PATH+'interim/NDVI_20200414.tif'\n",
    "ndvi(b4, b5, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Make Brightness temp -- Spring 2020-04-14\n",
    "data_in = PATH+'landsat/Level1/LC08_L1TP_041036_20200414_20200423_01_T1/'\n",
    "b_fn = data_in+'LC08_L1TP_041036_20200414_20200423_01_T1_B10.TIF'\n",
    "fn_out = PATH+'interim/BrightTemp_20200414.tif'\n",
    "radiance_mult = 3.3420E-04\n",
    "radiance_add = 0.10000\n",
    "k1 = 774.8853\n",
    "k2 = 1321.0789\n",
    "bright_temp(b_fn, fn_out, radiance_mult, radiance_add, k1, k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal(rst_in, polys_in, do_stats): \n",
    "    \"\"\"Function will run zonal stats on a raster and a set of polygons. All touched is set to True by default. \n",
    "    \n",
    "    Args:\n",
    "        rst_in = file name/path of raster to run zonal stats on\n",
    "        polys = either list of shape files (watersheds) or single shape file (countries)\n",
    "        do_stats = stats to use, see rasterstats package for documention, (use sume)\n",
    "    \"\"\"\n",
    "    \n",
    "    # switch crs\n",
    "    polys_in = polys_in.to_crs({'init' :'epsg:32611'}) # CRS of Landsat tifs\n",
    "    \n",
    "    # Run Zonal Stats\n",
    "    zs_feats = zonal_stats(polys_in, rst_in, stats= do_stats, geojson_out=True, all_touched=True)\n",
    "        \n",
    "    # Turn into geo data frame and rename column\n",
    "    zgdf = gpd.GeoDataFrame.from_features(zs_feats, crs=polys_in.crs)\n",
    "    \n",
    "    return zgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys_in =neighborhoods[['Name', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run Zonal stats - Throws error for Catalina Island which isn't in the scene \n",
    "rst_in = PATH+'interim/NDVI_20200414.tif'\n",
    "ndvi_spring = zonal(rst_in, polys_in, 'mean')\n",
    "ndvi_spring.rename(columns = {'mean' : 'NDVI_SPRING'}, inplace = True)\n",
    "\n",
    "rst_in = PATH+'interim/NDVI_20200820.tif'\n",
    "ndvi_summer = zonal(rst_in, polys_in, 'mean')\n",
    "ndvi_summer.rename(columns = {'mean' : 'NDVI_SUMMER'}, inplace = True)\n",
    "\n",
    "rst_in = PATH+'interim/BrightTemp_20200414.tif'\n",
    "temp_spring = zonal(rst_in, polys_in, 'mean')\n",
    "temp_spring.rename(columns = {'mean' : 'TEMP_SPRING'}, inplace = True)\n",
    "\n",
    "rst_in = PATH+'interim/BrightTemp_20200820.tif'\n",
    "temp_summer = zonal(rst_in, polys_in, 'mean')\n",
    "temp_summer.rename(columns = {'mean' : 'TEMP_SUMMER'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Merge it all together\n",
    "df_list = [ndvi_spring, ndvi_summer, temp_spring, temp_summer]\n",
    "\n",
    "for df in df_list:\n",
    "    df.rename(columns = {'Name' : 'NEIGHBORHOOD'}, inplace = True)\n",
    "    df_out = df_out.merge(df.iloc[:,1:3], on = 'NEIGHBORHOOD', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write CSV\n",
    "fn_out = 'ESM203_F2020_Ass1'\n",
    "df_out.to_csv(PATH+fn_out+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write shape file\n",
    "gdf_out = neighborhoods[['Name','geometry']]\n",
    "gdf_out.rename(columns={'Name':'NEIGHBORHOOD'}, inplace=True) # rename col\n",
    "gdf_out = df_out.merge(gdf_out, on = 'NEIGHBORHOOD', how = 'right')\n",
    "gdf_out = gpd.GeoDataFrame(gdf_out)\n",
    "gdf_out.to_file(PATH+fn_out+'.shp', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(df_out['NDVI_SUMMER'], np.log(df_out['CRIME PER CAPITA']))\n",
    "plt.xlim([0,.4])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
